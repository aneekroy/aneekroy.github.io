# FastVLM: Efficient Vision Encoding for VLMs

**Authors:** Pavan Kumar Anasosalu Vasu et al. (Apple)  
**Venue:** CVPR 2025  

## Abstract

FastViTHD hybrid encoder achieves 85x faster TTFT than LLaVA-OneVision. 3.4x smaller vision encoder. Eliminates need for token pruning via architecture.

## Metrics

- **Accuracy:** 86.5%
- **FLOPs:** 1.2G
- **Parameters:** 35.7M

## Tags

`Hybrid Encoder`, `Apple`, `SOTA`

## Methodology

FastViTHD hybrid encoder achieves 85x faster TTFT than LLaVA-OneVision. 3.4x smaller vision encoder. Eliminates need for token pruning via architecture.

## Future Directions

• Scaling the approach to larger model sizes and more diverse datasets.
• Investigating cross-task transfer learning capabilities.
• Exploring combinations with other efficiency techniques.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://arxiv.org/abs/2412.13303](https://arxiv.org/abs/2412.13303)

---

 
