# OmniVLM: Sub-Billion Parameter VLM for On-Device Inference

**Authors:** Various  
**Venue:** arXiv 2024  
**Paper ID:** 54

## Abstract

Token compression reduces visual sequence from 729 to 81 tokens. Sub-billion parameters enable efficient on-device deployment while maintaining visual-semantic fidelity.

## Metrics

- **Accuracy:** 79.0%
- **FLOPs:** 0.5G
- **Parameters:** 800M

## Tags

`Sub-Billion`, `On-Device`, `Compression`

## Methodology

Token compression reduces visual sequence from 729 to 81 tokens. Sub-billion parameters enable efficient on-device deployment while maintaining visual-semantic fidelity.

## Future Directions

• Scaling the approach to larger model sizes and more diverse datasets.
• Investigating cross-task transfer learning capabilities.
• Exploring combinations with other efficiency techniques.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://arxiv.org/pdf/2412.11475](https://arxiv.org/pdf/2412.11475)

---

 
