# MultiBench: Multiscale Benchmarks for Multimodal Representation Learning

**Authors:** Paul Pu Liang et al.  
**Venue:** NeurIPS 2021  
**Paper ID:** 10

## Abstract

Large-scale benchmark for multimodal learning with evaluation of time/space complexity. Reports inference time and memory for compact models suitable for mobile devices.

## Metrics

- **Accuracy:** 74.0%
- **FLOPs:** 2.0G
- **Parameters:** 50M

## Tags

`Benchmark`

## Methodology

Large-scale benchmark for multimodal learning with evaluation of time/space complexity. Reports inference time and memory for compact models suitable for mobile devices.

## Future Directions

• Scaling the approach to larger model sizes and more diverse datasets.
• Investigating cross-task transfer learning capabilities.
• Exploring combinations with other efficiency techniques.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/37693cfc748049e45d87b8c7d8b9aacd-Paper-round1.pdf](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/37693cfc748049e45d87b8c7d8b9aacd-Paper-round1.pdf)

---

*Generated from blogpost.html survey data*
