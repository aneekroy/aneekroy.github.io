# Glance2Gaze: Efficient Vision-Language Models

**Authors:** Juan Chen et al.  
**Venue:** NeurIPS 2025  

## Abstract

Two-stage visual token reduction: global 'glance' fusion + selective 'gaze' token compression. Improved performance with equal/lower compute.

## Metrics

- **Accuracy:** 86.2%
- **FLOPs:** 1.8G
- **Parameters:** 150M

## Tags

`Token Pruning`, `SOTA`

## Methodology

Two-stage visual token reduction: global 'glance' fusion + selective 'gaze' token compression. Improved performance with equal/lower compute.

Implements selective removal of less informative visual tokens based on attention scores or learned importance weights, reducing computational overhead during inference.

## Future Directions

• Exploring adaptive token budgets that vary based on task difficulty and input complexity.
• Investigating the combination of pruning and merging strategies for maximum efficiency.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://openreview.net/pdf?id=gm65gK3uOJ](https://openreview.net/pdf?id=gm65gK3uOJ)

---

 
