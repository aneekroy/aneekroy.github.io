# MQuant: Static Quantization for MLLMs

**Authors:** Jiayi Yu et al.  
**Venue:** ACM International Conference on Multimedia 2025  

## Abstract

Post-training W4A8 quantization for MLLMs. Addresses visual token latency and outliers. Achieves <1% accuracy degradation with 30% latency reduction.

## Metrics

- **Accuracy:** 86.0%
- **FLOPs:** 0.9G
- **Parameters:** 180M

## Tags

`Quantization`, `Inference`

## Methodology

Post-training W4A8 quantization for MLLMs. Addresses visual token latency and outliers. Achieves <1% accuracy degradation with 30% latency reduction.

Reduces model precision from floating-point to lower-bit representations, decreasing memory footprint and enabling faster inference on specialized hardware.

## Future Directions

• Scaling the approach to larger model sizes and more diverse datasets.
• Investigating cross-task transfer learning capabilities.
• Exploring combinations with other efficiency techniques.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://dl.acm.org/doi/pdf/10.1145/3746027.3755433](https://dl.acm.org/doi/pdf/10.1145/3746027.3755433)

---

 
