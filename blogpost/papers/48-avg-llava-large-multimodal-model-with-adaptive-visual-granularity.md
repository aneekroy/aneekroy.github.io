# AVG-LLaVA: Large Multimodal Model with Adaptive Visual Granularity

**Authors:** Zhibin Lan, Liqiang Niu, Fandong Meng, Wenbo Li, Jie Zhou, Jinsong Su  
**Venue:** ACL 2025  
**Paper ID:** 48

## Abstract

Adapts visual token granularity based on image complexity. Simple images use fewer tokens, complex images retain more detail.

## Metrics

- **Accuracy:** 83.0%
- **FLOPs:** 1.3G
- **Parameters:** 7.0B

## Tags

`Adaptive`, `Granularity`

## Methodology

Adapts visual token granularity based on image complexity. Simple images use fewer tokens, complex images retain more detail.

## Future Directions

• Scaling the approach to larger model sizes and more diverse datasets.
• Investigating cross-task transfer learning capabilities.
• Exploring combinations with other efficiency techniques.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://aclanthology.org/2025.findings-acl.865.pdf](https://aclanthology.org/2025.findings-acl.865.pdf)

---

*Generated from blogpost.html survey data*
