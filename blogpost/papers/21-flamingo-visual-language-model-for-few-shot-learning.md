# Flamingo: Visual Language Model for Few-Shot Learning

**Authors:** Jean-Baptiste Alayrac et al. (DeepMind)  
**Venue:** NeurIPS 2022  
**Paper ID:** 21

## Abstract

80B parameter VLM using Perceiver Resampler and gated cross-attention. Bridges frozen vision encoders with frozen LLMs. Achieves SOTA few-shot learning on 16 benchmarks.

## Metrics

- **Accuracy:** 82.0%
- **FLOPs:** 4.5G
- **Parameters:** 80.0B

## Tags

`Few-Shot`, `Cross-Attention`

## Methodology

80B parameter VLM using Perceiver Resampler and gated cross-attention. Bridges frozen vision encoders with frozen LLMs. Achieves SOTA few-shot learning on 16 benchmarks.

## Future Directions

• Scaling the approach to larger model sizes and more diverse datasets.
• Investigating cross-task transfer learning capabilities.
• Exploring combinations with other efficiency techniques.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://arxiv.org/abs/2204.14198](https://arxiv.org/abs/2204.14198)

---

*Generated from blogpost.html survey data*
