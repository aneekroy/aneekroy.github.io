# SparseVLM: Visual Token Sparsification for Efficient VLM Inference

**Authors:** Yuan Zhang et al.  
**Venue:** ICML 2025  
**Paper ID:** 30

## Abstract

Training-free text-guided token pruning and merging. Uses attention from text tokens to rank image token importance per layer. Achieves 54% FLOPs reduction, 37% lower latency while retaining 97% accuracy.

## Metrics

- **Accuracy:** 84.0%
- **FLOPs:** 1.4G
- **Parameters:** 7.0B

## Tags

`Sparse`, `Text-Guided`, `Training-Free`

## Methodology

Training-free text-guided token pruning and merging. Uses attention from text tokens to rank image token importance per layer. Achieves 54% FLOPs reduction, 37% lower latency while retaining 97% accuracy.

## Future Directions

• Scaling the approach to larger model sizes and more diverse datasets.
• Investigating cross-task transfer learning capabilities.
• Exploring combinations with other efficiency techniques.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://arxiv.org/abs/2410.04417](https://arxiv.org/abs/2410.04417)

---

 
