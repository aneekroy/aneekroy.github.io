# OpenVision: Cost-Effective Vision Encoders for Multimodal Learning

**Authors:** Xianhang Li et al.  
**Venue:** CVPR 2025  
**Paper ID:** 11

## Abstract

Fully open, cost-effective vision encoders (5.9M-632.1M params) enabling efficient multimodal models for edge devices. Matches or surpasses OpenAI CLIP.

## Metrics

- **Accuracy:** 85.5%
- **FLOPs:** 1.6G
- **Parameters:** 5.9M

## Tags

`Open-Source`, `Edge`

## Methodology

Fully open, cost-effective vision encoders (5.9M-632.1M params) enabling efficient multimodal models for edge devices. Matches or surpasses OpenAI CLIP.

## Future Directions

• Hardware-aware architecture search for specific edge devices.
• Exploring neural architecture search for optimal CNN-Transformer combinations.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://openaccess.thecvf.com](https://openaccess.thecvf.com)

---

 
