# PACT: Pruning and Clustering Token Reduction for Faster VLMs

**Authors:** Various  
**Venue:** CVPR 2025  
**Paper ID:** 47

## Abstract

Two-stage approach: first prunes unimportant tokens, then clusters similar remaining tokens. Preserves semantic information while reducing compute.

## Metrics

- **Accuracy:** 84.0%
- **FLOPs:** 1.0G
- **Parameters:** 7.0B

## Tags

`Pruning`, `Clustering`, `Two-Stage`

## Methodology

Two-stage approach: first prunes unimportant tokens, then clusters similar remaining tokens. Preserves semantic information while reducing compute.

## Future Directions

• Scaling the approach to larger model sizes and more diverse datasets.
• Investigating cross-task transfer learning capabilities.
• Exploring combinations with other efficiency techniques.
• Benchmarking on emerging multimodal tasks and real-world applications.

## Links

- **Paper:** [https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_PACT_Pruning_and_Clustering_Token_Reduction_for_Faster_VLMs_CVPR_2025_paper.pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_PACT_Pruning_and_Clustering_Token_Reduction_for_Faster_VLMs_CVPR_2025_paper.pdf)

---

*Generated from blogpost.html survey data*
